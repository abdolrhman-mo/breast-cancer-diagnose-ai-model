{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26179d16",
   "metadata": {},
   "source": [
    "**Phases 6-7: preprocessing, and training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe903a12",
   "metadata": {},
   "source": [
    "## **Phase 6: Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e981eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb114eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790251f1",
   "metadata": {},
   "source": [
    "### Remove useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52fa1e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop id column (not useful for the model) then check the info\n",
    "df.drop(['id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eeca46",
   "metadata": {},
   "source": [
    "### Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d02e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate What You Want to Predict\n",
    "X = df.drop('diagnosis', axis=1)  # Everything EXCEPT 'diagnosis' column\n",
    "y = df['diagnosis']               # ONLY the 'diagnosis' column\n",
    "\n",
    "# Note:\n",
    "# Why X and y?\n",
    "# This comes from math notation: y = f(X) means \"y depends on X\"\n",
    "# X: Independent variables (patient info)\n",
    "# y: Dependent variable (diagnosis)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544a2b32",
   "metadata": {},
   "source": [
    "## Handle class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d51e3e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentages:\n",
      "diagnosis\n",
      "0    62.637363\n",
      "1    37.362637\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check if your data is imbalanced\n",
    "print(\"\\nPercentages:\")\n",
    "print(y_train.value_counts(normalize=True) * 100)\n",
    "\n",
    "# Conclusion:\n",
    "# This is not too imbalanced (close to 60/40), so SMOTE or oversampling might not be essential, but you can still try it and see if recall improves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa1ad63",
   "metadata": {},
   "source": [
    "## Scale numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "365162fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes:\n",
    "# SMOTE = \"Synthetic Minority Oversampling TEchnique\"\n",
    "# What it means: \"I'm a tool that creates fake examples of rare cases\"\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8c105",
   "metadata": {},
   "source": [
    "## **Phase 7: Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0dabdd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression model...\n",
      "Training SVM model...\n",
      "Training XGBoost model...\n",
      "Training Random Forest model...\n",
      "Training Voting Classifier...\n",
      "Model training completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Logistic Regression model...\")\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Training SVM model...\")\n",
    "svm_model = SVC(kernel='linear', random_state=42, probability=True)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Training XGBoost model...\")\n",
    "# Calculate class weight for imbalanced data\n",
    "pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "xgb_model = XGBClassifier(\n",
    "    scale_pos_weight=pos_weight,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "# Note: xgb model handle imbalanced data better internally through scale_pos_weight\n",
    "\n",
    "print(\"Training Random Forest model...\")\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    class_weight='balanced',  # Handles imbalance\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Create voting classifier with your existing models\n",
    "print(\"Training Voting Classifier...\")\n",
    "voting_model = VotingClassifier([\n",
    "    ('lr', lr_model),       # Logistic Regression\n",
    "    ('svm', svm_model),     # SVM\n",
    "    ('rf', rf_model)        # Random Forest\n",
    "    # Note: Excluding XGBoost because it uses different data format\n",
    "], voting='soft')  # 'soft' uses probabilities, 'hard' uses direct votes\n",
    "voting_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Model training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb4a7662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "joblib.dump(X_train_scaled, \"../data/processed/X_train_scaled.pkl\")\n",
    "joblib.dump(y_train, \"../data/processed/y_train.pkl\")\n",
    "joblib.dump(X_test_scaled, \"../data/processed/X_test_scaled.pkl\")\n",
    "joblib.dump(y_test, \"../data/processed/y_test.pkl\")\n",
    "\n",
    "# Create models folder if it doesn't exist\n",
    "Path(\"../models\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save each model\n",
    "joblib.dump(lr_model, \"../models/logistic_regression.pkl\")\n",
    "joblib.dump(svm_model, \"../models/svm.pkl\")\n",
    "joblib.dump(rf_model, \"../models/random_forest.pkl\")\n",
    "joblib.dump(xgb_model, \"../models/xgboost.pkl\")\n",
    "joblib.dump(voting_model, \"../models/voting_classifier.pkl\")\n",
    "\n",
    "print(\"All models saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
